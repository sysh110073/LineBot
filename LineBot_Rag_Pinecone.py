import os
import sys
import io
import time
import json
import requests
import configparser
import hashlib
import hmac
import base64

from flask import Flask, request, abort

# LangChain & AI ç›¸é—œ
from langchain_core.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_classic.chains.conversational_retrieval.base import ConversationalRetrievalChain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone, ServerlessSpec
import urllib.request

# å¼·åˆ¶ UTF-8 è¼¸å‡º
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# ==========================================
# 1. è®€å–è¨­å®šæª”
# ==========================================
config = configparser.ConfigParser()
config.read('config.ini')

# è¨­å®šç’°å¢ƒè®Šæ•¸
os.environ["GOOGLE_API_KEY"] = config.get('line-bot', 'GOOGLE_API_KEY')
os.environ["PINECONE_API_KEY"] = config.get('line-bot', 'PINECONE_API_KEY')

LINE_CHANNEL_ACCESS_TOKEN = config.get('line-bot', 'channel_access_token')
LINE_CHANNEL_SECRET = config.get('line-bot', 'channel_secret')

# ==========================================
# 2. åˆå§‹åŒ– AI å¤§è…¦ (Pinecone RAG) - ä¿æŒä¸è®Š
# ==========================================
print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– AI å¤§è…¦ (é€£æ¥ Pinecone)...")
qa_chain = None 

def init_rag_system():
    global qa_chain
    try:
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        pc = Pinecone(api_key=os.environ.get("PINECONE_API_KEY"))
        index_name = "line-bot-bitcoin"

        # æª¢æŸ¥ä¸¦å»ºç«‹ Index
        if index_name not in pc.list_indexes().names():
            print(f"ğŸ“¦ ç´¢å¼• {index_name} ä¸å­˜åœ¨ï¼Œæ­£åœ¨å»ºç«‹ä¸­...")
            pc.create_index(
                name=index_name,
                dimension=384, 
                metric="cosine",
                spec=ServerlessSpec(cloud="aws", region="us-east-1")
            )
            while not pc.describe_index(index_name).status['ready']:
                time.sleep(1)

        index = pc.Index(index_name)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¸Šå‚³è³‡æ–™
        if index.describe_index_stats()['total_vector_count'] == 0:
            print("ğŸ“¥ é›²ç«¯è³‡æ–™åº«ç‚ºç©ºï¼Œé–‹å§‹ä¸‹è¼‰ä¸¦è™•ç† PDF...")
            pdf_filename = "bitcoin_paper.pdf"
            if not os.path.exists(pdf_filename):
                headers = {'User-Agent': 'Mozilla/5.0'}
                req = urllib.request.Request("https://bitcoin.org/bitcoin.pdf", headers=headers)
                with urllib.request.urlopen(req) as response, open(pdf_filename, 'wb') as out_file:
                    out_file.write(response.read())

            loader = PyPDFLoader(pdf_filename)
            docs = loader.load()
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            texts = text_splitter.split_documents(docs)
            
            PineconeVectorStore.from_documents(texts, embeddings, index_name=index_name)
            print("âœ… è³‡æ–™ä¸Šå‚³å®Œç•¢ï¼")
        
        vector_store = PineconeVectorStore.from_existing_index(index_name, embeddings)
        retriever = vector_store.as_retriever(search_kwargs={"k": 2})
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

        custom_template = """
        ä½ æ˜¯é»ƒæ°ä¼æ¥­çš„ AI åŠ©ç†ã€‚è«‹æ ¹æ“šä¸‹æ–¹çš„ã€åƒè€ƒæ–‡ä»¶ã€‘å›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚
        å¦‚æœã€åƒè€ƒæ–‡ä»¶ã€‘ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œä½ å¯ä»¥é‹ç”¨ä½ åŸæœ¬çš„çŸ¥è­˜ä¾†å›ç­”ï¼Œä½†è«‹èªªæ˜é€™æ˜¯ä½ çš„è£œå……çŸ¥è­˜ã€‚
        
        ã€åƒè€ƒæ–‡ä»¶ã€‘ï¼š
        {context}
        
        ç”¨æˆ¶å•é¡Œï¼š{question}
        å›ç­”ï¼š
        """
        PROMPT = PromptTemplate(template=custom_template, input_variables=["context", "question"])

        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=retriever,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": PROMPT}
        )
        print("âœ… AI ç³»çµ±æº–å‚™å°±ç·’ï¼")

    except Exception as e:
        print(f"âŒ RAG åˆå§‹åŒ–å¤±æ•—: {e}")

init_rag_system()

# ==========================================
# 3. è¨˜æ†¶é«”ç®¡ç†
# ==========================================
user_histories = {}

# ==========================================
# 4. å®šç¾©ç™¼é€è¨Šæ¯å‡½å¼ (ç´” Requests)
# ==========================================
def reply_to_line(reply_token, message_text):
    api_url = "https://api.line.me/v2/bot/message/reply"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"
    }
    # å»ºæ§‹ JSON Body
    payload = {
        "replyToken": reply_token,
        "messages": [
            {
                "type": "text",
                "text": message_text
            }
        ]
    }
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        response.raise_for_status() # å¦‚æœæ˜¯ 4xx æˆ– 5xx æœƒå ±éŒ¯
    except Exception as e:
        print(f"âš ï¸ å›è¦†è¨Šæ¯å¤±æ•—: {e}, å›æ‡‰å…§å®¹: {response.text}")

# ==========================================
# 5. Flask Server (æ‰‹å‹•è™•ç† Webhook)
# ==========================================
app = Flask(__name__)

@app.route("/callback", methods=['POST'])
def callback():
    # 1. å–å¾— Header ä¸­çš„ç°½ç« 
    signature = request.headers.get('X-Line-Signature', '')
    
    # 2. å–å¾— Body å…§å®¹ (å­—ä¸²æ ¼å¼)
    body = request.get_data(as_text=True)

    # 3. æ‰‹å‹•é©—è­‰ç°½ç«  (å®‰å…¨æ©Ÿåˆ¶)
    # æ¼”ç®—æ³•ï¼šHMAC-SHA256(ChannelSecret, Body) ç„¶å¾Œè½‰ Base64
    try:
        hash_val = hmac.new(
            LINE_CHANNEL_SECRET.encode('utf-8'),
            body.encode('utf-8'),
            hashlib.sha256
        ).digest()
        computed_signature = base64.b64encode(hash_val).decode('utf-8')
        
        if signature != computed_signature:
            print("âŒ ç°½ç« é©—è­‰å¤±æ•—ï¼å¯èƒ½æ˜¯ä¸åˆæ³•çš„è«‹æ±‚ã€‚")
            return 'Invalid signature', 400
    except Exception as e:
        print(f"âŒ é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 'Error', 500

    # 4. è§£æ JSON ä¸¦è™•ç†äº‹ä»¶
    try:
        events_data = json.loads(body) # å°‡ JSON å­—ä¸²è½‰ç‚º Python Dict
        events = events_data.get('events', [])

        for event in events:
            # åªè™•ç†æ–‡å­—è¨Šæ¯äº‹ä»¶
            if event.get('type') == 'message' and event['message'].get('type') == 'text':
                
                user_msg = event['message']['text']
                reply_token = event['replyToken']
                user_id = event['source']['userId']
                
                print(f"ğŸ‘¤ ç”¨æˆ¶({user_id[:5]}...) èªª: {user_msg}")

                # è‹¥ AI é‚„æ²’å¥½
                if qa_chain is None:
                    reply_to_line(reply_token, "ç³»çµ±å•Ÿå‹•ä¸­ï¼Œè«‹ç¨å¾Œ...")
                    continue

                # ---- RAG é‚è¼¯é–‹å§‹ ----
                chat_history = user_histories.get(user_id, [])
                
                result = qa_chain.invoke({
                    "question": user_msg, 
                    "chat_history": chat_history
                })
                answer = result['answer']
                
                # æ›´æ–°è¨˜æ†¶
                chat_history.append((user_msg, answer))
                if len(chat_history) > 5: chat_history.pop(0)
                user_histories[user_id] = chat_history
                # ---- RAG é‚è¼¯çµæŸ ----

                # ç™¼é€å›è¦† (Call Requests)
                reply_to_line(reply_token, answer)

    except Exception as e:
        print(f"âŒ è™•ç†è¨Šæ¯å¤±æ•—: {e}")
        return 'Error', 500
    
    return 'OK', 200

if __name__ == "__main__":
    app.run(port=5001)
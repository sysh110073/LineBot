import os
import io
import sys
import urllib.request # ç”¨ä¾†ä¸‹è¼‰ç¯„ä¾‹ PDF
# å¼·åˆ¶å°‡æ¨™æº–è¼¸å‡º (stdout) è¨­å®šç‚º utf-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import configparser

# è¨­å®šä½ çš„ Key
config = configparser.ConfigParser()
config.read('config.ini')

# è¨­å®šç’°å¢ƒè®Šæ•¸
os.environ["GOOGLE_API_KEY"] = config.get('line-bot', 'GOOGLE_API_KEY')

print("ğŸš€ æ­£åœ¨è¼‰å…¥æ¨¡çµ„...")

try:
    # è¼‰å…¥ PDF ç›¸é—œå·¥å…·
    from langchain_community.document_loaders import PyPDFLoader
    # è¼‰å…¥å¿…è¦çš„ RAG å·¥å…·
    from langchain_text_splitters import RecursiveCharacterTextSplitter # ğŸ‘ˆ æ¯”è¼ƒé«˜ç´šçš„åˆ‡å¡Šå·¥å…·
    from langchain_community.document_loaders import TextLoader
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_classic.chains.retrieval_qa.base import RetrievalQA
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError as e:
    print(f"âŒ æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
    sys.exit(1)

# ==========================================
# æ­¥é©Ÿ 1ï¼šå–å¾— PDF æª”æ¡ˆ
# ==========================================
pdf_filename = "bitcoin_paper.pdf"

# å¦‚æœé›»è…¦è£¡æ²’æœ‰é€™å€‹æª”æ¡ˆï¼Œå°±è‡ªå‹•å¾ç¶²è·¯ä¸‹è¼‰
if not os.path.exists(pdf_filename):
    print("ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ç¯„ä¾‹ PDF (æ¯”ç‰¹å¹£ç™½çš®æ›¸)...")
    url = "https://bitcoin.org/bitcoin.pdf"
    urllib.request.urlretrieve(url, pdf_filename)
    print("âœ… ä¸‹è¼‰å®Œæˆï¼")
else:
    print("âœ… åµæ¸¬åˆ°æª”æ¡ˆå·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨ã€‚")

# ==========================================
# æ­¥é©Ÿ 2ï¼šè®€å– & åˆ‡å‰² PDF (Chunking)
# ==========================================
print("ğŸ“– æ­£åœ¨è®€å–ä¸¦åˆ‡å‰² PDF...")

# 1. è¼‰å…¥å™¨
loader = PyPDFLoader(pdf_filename)
# è¼‰å…¥æ‰€æœ‰é é¢
documents = loader.load()

# 2. åˆ‡å‰²å™¨ (Splitter)
# chunk_size=1000: æ¯å¡Šç´„ 1000 å€‹å­—å…ƒ
# chunk_overlap=200: æ¯å¡Šä¹‹é–“é‡ç–Š 200 å­— (é¿å…åˆ‡æ–·ä¸Šä¸‹æ–‡)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, 
    chunk_overlap=200
)
# é–‹å§‹åˆ‡å‰²
texts = text_splitter.split_documents(documents)

print(f"âœ… åˆ‡å‰²å®Œæˆï¼åŸæœ¬ {len(documents)} é çš„ PDFï¼Œè¢«åˆ‡æˆäº† {len(texts)} å€‹å°æ®µè½ã€‚")
# è®“æˆ‘å€‘å·çœ‹ç¬¬ 1 æ®µé•·ä»€éº¼æ¨£
print(f"ğŸ” ç¯„ä¾‹æ®µè½å†…å®¹: {texts[0].page_content[:100]}...")

# ==========================================
# æ­¥é©Ÿ 3ï¼šå‘é‡åŒ– & å­˜å…¥è³‡æ–™åº«
# ==========================================
print("â³ æ­£åœ¨å»ºç«‹å‘é‡ç´¢å¼• (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)...")

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
db = Chroma.from_documents(texts, embeddings)

print("âœ… è³‡æ–™åº«æº–å‚™å°±ç·’ï¼")

# ==========================================
# æ­¥é©Ÿ 4ï¼šå»ºç«‹å•ç­”éˆ & æå•
# ==========================================
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
retriever = db.as_retriever(search_kwargs={"k": 3}) # æ”¹æˆæ‰¾å‰ 3 å€‹ç›¸é—œæ®µè½
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever)

# --- æ¸¬è©¦å•é¡Œ ---
query = "ä»€éº¼æ˜¯ Proof of Workï¼Ÿ"

print(f"\nğŸ™‹â€â™‚ï¸ ä½ çš„å•é¡Œï¼š{query}")
print("ğŸ¤– AI æ­£åœ¨é–±è®€ç™½çš®æ›¸ä¸¦æ€è€ƒä¸­...")

try:
    response = qa.invoke(query)
    answer = response['result'] if isinstance(response, dict) else response
    print("\nğŸ“ AI çš„å›ç­”ï¼š")
    print(answer)
except Exception as e:
    print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
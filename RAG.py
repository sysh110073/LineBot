import os
import sys
import configparser

# è¨­å®šä½ çš„ Key
config = configparser.ConfigParser()
config.read('config.ini')

# è¨­å®šç’°å¢ƒè®Šæ•¸
os.environ["GOOGLE_API_KEY"] = config.get('line-bot', 'GOOGLE_API_KEY')

print("ğŸš€ æ­£åœ¨è¼‰å…¥æ¨¡çµ„ï¼Œè«‹ç¨å€™...")

try:
    # è¼‰å…¥å¿…è¦çš„ RAG å·¥å…·
    from langchain_text_splitters import CharacterTextSplitter
    from langchain_community.document_loaders import TextLoader
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_classic.chains.retrieval_qa.base import RetrievalQA
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError as e:
    print(f"âŒ æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
    sys.exit(1)

# ==========================================
# æ­¥é©Ÿ 1ï¼šæº–å‚™ç§æœ‰è³‡æ–™ (ç§˜å¯†é£Ÿè­œ)
# ==========================================
secret_recipe = """
ã€é»ƒæ°å®¶å‚³ç‰¹è£½æ»·è‚‰é£¯é£Ÿè­œã€‘
1. è±¬è‚‰é¸æ“‡ï¼šå¿…é ˆä½¿ç”¨ã€Œæ¢…èŠ±è‚‰ã€èˆ‡ã€Œäº”èŠ±è‚‰ã€ä»¥ 3:7 çš„æ¯”ä¾‹æ··åˆï¼Œé€™æ˜¯å£æ„Ÿæ»‘é †çš„é—œéµã€‚
2. éˆé­‚é†¬æ±ï¼šç‡‰ç…®æ™‚ä¸èƒ½åŠ æ°´ï¼Œå¿…é ˆå…¨ä½¿ç”¨ã€Œå¯å£å¯æ¨‚ã€ä»£æ›¿æ°´ï¼Œé€™æ¨£è‚‰è³ªæœƒè»Ÿå«©ä¸”å¸¶æœ‰ç„¦ç³–é¦™ã€‚
3. ç§˜å¯†é¦™æ–™ï¼šèµ·é‹å‰äº”åˆ†é˜ï¼ŒåŠ å…¥ä¸€å°åŒ™ã€Œå³æº¶å’–å•¡ç²‰ã€ï¼Œèƒ½æå‡é†¬æ±çš„å±¤æ¬¡æ„Ÿã€‚
4. ç‡‰ç…®æ™‚é–“ï¼šå¤§ç«ç…®æ»¾å¾Œï¼Œè½‰å¾®ç«æ…¢ç‡‰ 4 å°æ™‚ 20 åˆ†ã€‚
"""

# æŠŠæ–‡å­—åŒ…è£æˆ LangChain çœ‹å¾—æ‡‚çš„ Document æ ¼å¼
# é€™è£¡æˆ‘å€‘æ¨¡æ“¬æŠŠæ–‡å­—åˆ‡æˆå°å¡Š (Chunk)ï¼Œé›–ç„¶é€™æ®µæ–‡å­—å¾ˆçŸ­ï¼Œä½†é€™æ˜¯ RAG çš„æ¨™æº–å‹•ä½œ
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)
texts = text_splitter.create_documents([secret_recipe])

print(f"âœ… è³‡æ–™æº–å‚™å®Œæˆï¼Œå…±æœ‰ {len(texts)} å€‹æ®µè½ã€‚")

# ==========================================
# æ­¥é©Ÿ 2ï¼šæ–‡å­—å‘é‡åŒ– & å­˜å…¥è³‡æ–™åº«
# ==========================================
print("â³ æ­£åœ¨ä¸‹è¼‰ä¸¦åˆå§‹åŒ–å‘é‡æ¨¡å‹ (ç¬¬ä¸€æ¬¡æœƒæ¯”è¼ƒä¹…)...")

# ä½¿ç”¨å…è²»çš„ HuggingFace æ¨¡å‹å°‡æ–‡å­—è½‰æˆå‘é‡ (ä¸ç”¨èŠ±éŒ¢å‘¼å« OpenAI/Google Embedding API)
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# å»ºç«‹æš«æ™‚æ€§çš„å‘é‡è³‡æ–™åº« (å­˜åœ¨è¨˜æ†¶é«”ä¸­ï¼Œç¨‹å¼é—œæ‰å°±æœƒæ¶ˆå¤±)
db = Chroma.from_documents(texts, embeddings)

print("âœ… å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼è³‡æ–™å·²å­˜å…¥ã€‚")

# ==========================================
# æ­¥é©Ÿ 3ï¼šå»ºç«‹å•ç­”éˆ (RAG Chain)
# ==========================================
# æº–å‚™å¤§è…¦ (Gemini)
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

# æŠŠè³‡æ–™åº«è®Šæˆä¸€å€‹ã€Œæœå°‹å¼•æ“ (Retriever)ã€
retriever = db.as_retriever(search_kwargs={"k": 1}) # k=1 ä»£è¡¨åªæ‰¾æœ€ç›¸é—œçš„é‚£ 1 æ®µ

# å»ºç«‹å•ç­”éˆï¼šå®ƒæœƒè‡ªå‹•åšã€Œæœå°‹ -> å¡å…¥ Prompt -> å• AIã€çš„æµç¨‹
qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever)

# ==========================================
# æ­¥é©Ÿ 4ï¼šé–‹å§‹æ¸¬è©¦ï¼
# ==========================================
query = "è«‹å•é»ƒæ°æ»·è‚‰é£¯çš„ç§˜å¯†é¦™æ–™æ˜¯ä»€éº¼ï¼Ÿé‚„æœ‰è¦ç‡‰å¤šä¹…ï¼Ÿ"

print(f"\nğŸ™‹â€â™‚ï¸ ä½ çš„å•é¡Œï¼š{query}")
print("ğŸ¤– AI æ­£åœ¨ç¿»é–±é£Ÿè­œä¸¦æ€è€ƒä¸­...")

response = qa.invoke(query)

# å°å‡ºçµæœ
print("\nğŸ“ AI çš„å›ç­”ï¼š")
# è™•ç†ä¸åŒç‰ˆæœ¬çš„å›å‚³æ ¼å¼ (æœ‰çš„ç‰ˆæœ¬å›å‚³å­—ä¸²ï¼Œæœ‰çš„å›å‚³å­—å…¸)
answer = response['result'] if isinstance(response, dict) else response
print(answer)